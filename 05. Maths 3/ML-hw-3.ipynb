{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8679c95",
   "metadata": {},
   "source": [
    "# Домашнее задание 3\n",
    "## Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31eaaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f493bc",
   "metadata": {},
   "source": [
    "### Ridge-регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b964e7",
   "metadata": {},
   "source": [
    "Рассматриваем модель Ridge-регрессии (с $L_2$-регуляризацией):\n",
    "\n",
    "$$Q = \\| Y - X\\omega \\|^2 + \\lambda \\| \\omega \\|^2$$\n",
    "$$dQ\\big|_{\\omega_{*}} = d(\\| Y - X\\omega \\|^2) + \\lambda d(\\|\\omega \\|^2)$$\n",
    "Отдельно посчитаем $d(\\|\\omega \\|^2)\\big|_{\\omega_{*}} = d(<\\omega, \\omega>)\\big|_{\\omega_{*}} = 2\\omega_{*}$. Тогда по известной с лекции формулы для ошибки:\n",
    "$$dQ\\big|_{\\omega_{*}} = -2\\mathbb{X}^T<\\mathbb{Y} - \\mathbb{X}\\omega, \\omega_{*}> + 2\\lambda \\omega_{*} = <-2\\mathbb{X}^T(\\mathbb{Y} - \\mathbb{X}\\omega_{*}) + 2\\lambda E, \\omega_{*}>$$\n",
    "Тогда $$\\nabla_{\\omega}Q = 2\\lambda E - 2\\mathbb{X}^T(\\mathbb{Y} - \\mathbb{X}\\omega) = 2\\lambda E + 2\\mathbb{X}^T(\\mathbb{X}\\omega - \\mathbb{Y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2da179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class RidgeLinReg(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, batch_size=25, num_steps=350, lr=1e-2, lambd=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        batch_size = self.batch_size\n",
    "        w = np.random.randn(X.shape[1])[:, None]\n",
    "        n_objects = len(X)\n",
    "\n",
    "        for i in range(self.num_steps):\n",
    "            sample_indices = np.random.randint(0, n_objects, size=batch_size)\n",
    "            w -= 2 * self.lr * (self.lambd * w + np.dot(X[sample_indices].T, np.dot(X[sample_indices], w) - Y[sample_indices])) / self.batch_size\n",
    "\n",
    "        self.w = w\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X @ self.w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447fad1",
   "metadata": {},
   "source": [
    "Сравним с моделью из Sklearn, воспользовавшись кодом с лекции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263186af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "n_features = 700\n",
    "n_objects = 100000\n",
    "\n",
    "w_true = np.random.uniform(-2, 2, (n_features, 1))\n",
    "\n",
    "X = np.random.uniform(-100, 100, (n_objects, n_features)) * np.arange(n_features)\n",
    "Y = X.dot(w_true) + np.random.normal(0, 10, (n_objects, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8e44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be9815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb1ff524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 in own model: 0.9978136453703507\n",
      "R^2 in sklearn loss: 0.9999999996210158\n"
     ]
    }
   ],
   "source": [
    "own_model = RidgeLinReg().fit(x_scaled, y_train)\n",
    "y_pred = own_model.predict(x_test_scaled)\n",
    "own_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "sklearn_model = Ridge().fit(x_scaled, y_train)\n",
    "y_pred = sklearn_model.predict(x_test_scaled)\n",
    "\n",
    "sklearn_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('R^2 in own model:', own_r2)\n",
    "print('R^2 in sklearn loss:', sklearn_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f181df5",
   "metadata": {},
   "source": [
    "Видим, что реализованная регрессия мало уступает модели \"из коробки\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e211000",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84b700",
   "metadata": {},
   "source": [
    "Вычислим градиент для функции log-loss: $$\\nabla Q = X^T * (-Y * \\frac{e^{X^T * (-Y) * \\omega}}{1 + e^{X^T * (-Y) * \\omega}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "296358db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class LogReg(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, num_steps=350, lr=1e-2):\n",
    "        self.num_steps = num_steps\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        batch_size = self.batch_size\n",
    "        w = np.random.randn(X.shape[1])\n",
    "        n_objects = len(X)\n",
    "        \n",
    "        for i in range(self.num_steps):\n",
    "            sample_indices = np.random.randint(0, n_objects, size=batch_size)\n",
    "            w -= self.lr * (np.dot(X.T, -Y * (np.exp(np.dot(np.dot(X.T, -Y).T, w))) / (1 + np.exp(np.dot(np.dot(X.T, -Y).T, w)))))\n",
    "        self.w = w\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = 1 / (1 + np.exp(-X @ self.w))\n",
    "        for i in range(0, len(y)):\n",
    "            if y[i] > 0.5:\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "6b65f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, Y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "b1330363",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "5bacc52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "3f30e868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in own model: 0.9440559440559441\n",
      "Score in sklearn loss: 0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "own_model = LogReg().fit(x_scaled, y_train)\n",
    "y_pred = own_model.predict(x_test_scaled)\n",
    "own_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "sklearn_model = LogisticRegression().fit(x_scaled, y_train)\n",
    "y_pred = sklearn_model.predict(x_test_scaled)\n",
    "\n",
    "sklearn_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Score in own model:', own_score)\n",
    "print('Score in sklearn loss:', sklearn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb35f7",
   "metadata": {},
   "source": [
    "Снова получили неплохой результат"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
