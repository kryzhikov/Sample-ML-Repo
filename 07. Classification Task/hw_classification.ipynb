{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZhHbAIcsu37"
   },
   "source": [
    "# Домашнее задание\n",
    "\n",
    "Всего у вас 2 домашних задания:\n",
    "\n",
    "### 1) Бинарная классификация на примере детекции фрода на кредитных картах (6 баллов)\n",
    "(в этом файле)\n",
    "\n",
    "### 2) Небинарная классификация на вашем датасете (6 баллов)\n",
    "(тоже в этом файле)\n",
    "\n",
    "# 1 - Бинарная классификация на примере детекции фрода на кредитных картах (суммарно 6 баллов)\n",
    "У вас есть информация о множесте транзакций. Вам нужно научиться предсказывать, какие из них мошеннические, а какие нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDoZ9yhUsu3-"
   },
   "source": [
    "### (1 балл) Считайте данные\n",
    "Сами считайте и предобработайте, если надо, данные из файла creditcard.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TjQnsl6Hsu3_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "n68Nqnbmsu3_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\", delimiter = ',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnvlEyPzsu4A"
   },
   "source": [
    "### (2 балла) Обучите несколько моделей, посмотрите на метрики.\n",
    "Как модели точно возьмите LogisticRegression, KNN и константу, можете придумать еще какие-нибудь.\n",
    "\n",
    "Как метрики точно возьмите accuracy, precision, recall, f1, roc_auc. Постройте ROC-кривую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GTJQis6su4A"
   },
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "6n2ssmPZsu4A"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=3000) \n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Константа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_const = np.zeros(len(X_test))\n",
    "y_pred_proba_const = y_pred_const\n",
    "y_pred_proba_const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3) # выберем K=5 например\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_proba_knn = knn.predict_proba(X_test)[:, 1]  # оставили только второй столбец\n",
    "y_pred_proba_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999133925541004\n",
      "0.9985955549313578\n",
      "0.9984082955888721\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_log_reg))\n",
    "print(accuracy_score(y_test, y_pred_proba_knn.round()))\n",
    "print(accuracy_score(y_test, y_pred_proba_const))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7818181818181819\n",
      "1.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_pred_log_reg))\n",
    "print(precision_score(y_test, y_pred_proba_knn.round()))\n",
    "print(precision_score(y_test, y_pred_proba_const))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6991869918699187\n",
      "0.21052631578947367\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred_log_reg))\n",
    "print(f1_score(y_test, y_pred_proba_knn.round()))\n",
    "print(f1_score(y_test, y_pred_proba_const))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roc-auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8160358021788433\n",
      "0.5588235294117647\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, y_pred_log_reg))\n",
    "print(roc_auc_score(y_test, y_pred_proba_knn.round()))\n",
    "print(roc_auc_score(y_test, y_pred_proba_const))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6323529411764706\n",
      "0.11764705882352941\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test, y_pred_log_reg))\n",
    "print(recall_score(y_test, y_pred_proba_knn.round()))\n",
    "print(recall_score(y_test, y_pred_proba_const))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-кривая (а почему так получилось...так же не должно) (я починил, я тупой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conqu\\AppData\\Local\\Temp\\ipykernel_14324\\344427919.py:6: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(fpr, tpr, 'b', linewidth=3, color = 'red')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# я понял, где я тупой!!!\n",
    "y_pred_n_log_reg = log_reg.predict_proba(X_test)[:, 1]  # сорян я это прям тут оставлю\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_n_log_reg)\n",
    "plt.plot(fpr, tpr, 'b', linewidth=3, color = 'red')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot([0, 0], [0, 1], 'k')\n",
    "plt.plot([1, 1], [0, 1], 'k')\n",
    "plt.plot([0, 1], [0, 0], 'k')\n",
    "plt.plot([0, 1], [1, 1], 'k')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((0, 1))\n",
    "plt.axis('equal')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conqu\\AppData\\Local\\Temp\\ipykernel_14324\\1387230144.py:3: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(fpr, tpr, 'b', linewidth = 3, color = 'red')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_knn)\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(fpr, tpr, 'b', linewidth = 3, color = 'red')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot([0, 0], [0, 1], 'k')\n",
    "plt.plot([1, 1], [0, 1], 'k')\n",
    "plt.plot([0, 1], [0, 0], 'k')\n",
    "plt.plot([0, 1], [1, 1], 'k')\n",
    "plt.xlabel('Falce positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((0, 1))\n",
    "plt.axis('equal')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXJuJJUTsu4B"
   },
   "source": [
    "### (1 балл) Выберите одну метрику, которую вы будете максимизировать\n",
    "\n",
    "Представьте, что вы решаете задачу автоматического поиска мошеннических транзакций, чтобы ваш робот автоматически банил пользователей, который их осуществляют.\n",
    "\n",
    "Обоснуйте свой выбор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле, варианта два.\n",
    "Нам абсолютно точно нужно максимизировать количество найденных сволочей (читать как преступников).\n",
    "Но при этом при постоянном бане не тех польхователей хоть и можно написать в поддержку, но польхователи будут расстраиваться и закидывать болтами банк за несправедливый бан.\n",
    "По причине того, что мы любим наших пользователей, будем максимизировать f1.\n",
    "Но также можно попробовать намутить recall - но там мы будем просто банить всех подряд, и будет жалко обычных работяг с завода.\n",
    "Т.к. метрика только одна, берем f1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cycL8EEQsu4B"
   },
   "source": [
    "### (2 балла) Переберите гиперпараметры разных моделей, попытайтесь добиться лучшего результата по этой метрике\n",
    "\n",
    "Постройте график для каждого перебора, сделайте красивый отчет (не надо просто говорить \"я решил выбрать 2, 0.7 и 6, так не пойдет\".\n",
    "\n",
    "Можно преобразовывать датасет, преобразовывать, добавлять, удалять фичи, всё что угодно.\n",
    "\n",
    "Отсутствие результата тоже результат (вдруг вы перебрали кучу вещей, а лучший все еще самый первый запуск, главное что перебрали)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.7207914         nan 0.67769101 0.71712916]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best:  {'penalty': 'l1', 'solver': 'liblinear'}\n",
      "f1 score: 0.7207913993696525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {'penalty': ['elasticnet', 'l1', 'l2'],\n",
    "        \"solver\": ['liblinear', 'newton-cg']}\n",
    "log_reg = LogisticRegression()\n",
    "log_reg_grid = GridSearchCV(log_reg, grid, scoring=\"f1\")\n",
    "log_reg_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"best: \", log_reg_grid.best_params_)\n",
    "print(\"f1 score:\", log_reg_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### попробуем перебрать кф регуляризации и выбрать лучший с наиб. показателем f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef is: 0.01\n",
      "Score: 0.5527997685675176\n",
      "\n",
      "coef is: 0.21000000000000002\n",
      "Score: 0.7026223776223776\n",
      "\n",
      "coef is: 0.41000000000000003\n",
      "Score: 0.6979296336318486\n",
      "\n",
      "coef is: 0.6100000000000001\n",
      "Score: 0.7010031554378554\n",
      "\n",
      "coef is: 0.81\n",
      "Score: 0.7000950027030773\n",
      "\n",
      "coef is: 1.01\n",
      "Score: 0.7015229912791687\n",
      "\n",
      "coef is: 1.2100000000000002\n",
      "Score: 0.7010334823456307\n",
      "\n",
      "coef is: 1.4100000000000001\n",
      "Score: 0.7010334823456307\n",
      "\n",
      "coef is: 1.61\n",
      "Score: 0.7003359950881863\n",
      "\n",
      "coef is: 1.81\n",
      "Score: 0.7003359950881863\n",
      "\n",
      "coef is: 2.01\n",
      "Score: 0.7003359950881863\n",
      "\n",
      "coef is: 2.21\n",
      "Score: 0.7003359950881863\n",
      "\n",
      "coef is: 2.41\n",
      "Score: 0.7003359950881863\n",
      "\n",
      "coef is: 2.61\n",
      "Score: 0.6986207292219772\n",
      "\n",
      "coef is: 2.81\n",
      "Score: 0.7010334823456307\n",
      "\n",
      "coef is: 3.01\n",
      "Score: 0.7003359950881863\n",
      "\n",
      "coef is: 3.21\n",
      "Score: 0.7003359950881863\n",
      "\n",
      "coef is: 3.41\n",
      "Score: 0.7003359950881863\n",
      "\n",
      "coef is: 3.61\n",
      "Score: 0.7003359950881863\n",
      "\n",
      "coef is: 3.81\n",
      "Score: 0.7003359950881863\n",
      "\n",
      "coef is: 4.01\n",
      "Score: 0.7010334823456307\n",
      "\n",
      "coef is: 4.21\n",
      "Score: 0.7010334823456307\n",
      "\n",
      "coef is: 4.41\n",
      "Score: 0.7010334823456307\n",
      "\n",
      "coef is: 4.61\n",
      "Score: 0.7010334823456307\n",
      "\n",
      "coef is: 4.8100000000000005\n",
      "Score: 0.7010334823456307\n",
      "\n",
      "coef is: 5.01\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 5.21\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 5.41\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 5.61\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 5.8100000000000005\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 6.01\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 6.21\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 6.41\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 6.61\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 6.8100000000000005\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 7.01\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 7.21\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 7.41\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 7.61\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 7.8100000000000005\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 8.01\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 8.21\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 8.41\n",
      "Score: 0.7001328236549464\n",
      "\n",
      "coef is: 8.61\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 8.81\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 9.01\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 9.21\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 9.41\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 9.610000000000001\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 9.81\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 10.01\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 10.21\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 10.41\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 10.610000000000001\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 10.81\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 11.01\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 11.21\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 11.41\n",
      "Score: 0.698932191743414\n",
      "\n",
      "coef is: 11.610000000000001\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 11.81\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 12.01\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 12.21\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 12.41\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 12.610000000000001\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 12.81\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 13.01\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 13.21\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 13.41\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 13.610000000000001\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 13.81\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 14.01\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 14.21\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 14.41\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 14.610000000000001\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 14.81\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 15.01\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 15.21\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 15.41\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 15.610000000000001\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 15.81\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 16.01\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 16.21\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 16.410000000000004\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 16.610000000000003\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 16.810000000000002\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 17.01\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 17.21\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 17.410000000000004\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 17.610000000000003\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 17.810000000000002\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 18.01\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 18.21\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 18.410000000000004\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 18.610000000000003\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 18.810000000000002\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 19.01\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 19.210000000000004\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 19.410000000000004\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 19.610000000000003\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 19.810000000000002\n",
      "Score: 0.6979325619766611\n",
      "\n",
      "coef is: 20.01\n",
      "Score: 0.6979325619766611\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for coef in np.arange(0.01, 20.02, 0.2):\n",
    "    print(\"coef is:\", coef)\n",
    "    upgr_model = LogisticRegression(penalty=\"l1\", solver='liblinear',  C=coef, random_state=42)\n",
    "    \n",
    "    score = cross_val_score(upgr_model, X, y, scoring=\"f1\").mean()\n",
    "    print('Score:', score)\n",
    "    scores.append(score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best is: 0.7026223776223776\n",
      "index is: 1\n"
     ]
    }
   ],
   "source": [
    "best = max(scores)\n",
    "print(\"best is:\", best)\n",
    "print(\"index is:\", scores.index(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ef95597730>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0.01, 20.02, 0.2), scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика можно сделать 2 вывода:\n",
    "1. Стоило начать перебирать с большим изменением параметра\n",
    "2. Лучшее значение достигается при начальном кф регуляризации, лучшее значение = 0.7026223776223776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Продолжим страдания с KNN (кста качество на log reg чутка выросло)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best:  {'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "f1 score: 0.35206706964863793\n"
     ]
    }
   ],
   "source": [
    "grid_knn = {'n_neighbors': np.arange(2,6,1), \n",
    "        'metric': ['euclidean', 'manhattan'], \n",
    "        'weights': ['uniform', 'distance']\n",
    "        }\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, grid_knn, scoring=\"f1\")\n",
    "knn_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"best: \", knn_cv.best_params_)\n",
    "print(\"f1 score:\", knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ска и ради этого я ждал до 6 утра..\n",
    "\n",
    "Реальный вопрос к проверяющим! Интересно услышать ответ - напишите, пожалуйста\n",
    "Вот эта модель KNN обучалась ОЧЕНЬ долго - сейчас время 5:58, а она только закончилась (началось обучение примерно часа в 2 ночи, т.е. по факту 4 часа прошло)\n",
    "Вопрос - почему так долго длится обучение, хотя железо не самое плохое, и какие есть варианты это ускорить? Ну кроме апгрейда железа\n",
    "Спасибо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of neighnours is: 2\n",
      "Score: 0.0017425013540888234\n",
      "Time wasted: 0:39:50.692334\n",
      "\n",
      "number of neighnours is: 3\n",
      "Score: 0.0016391250866096979\n",
      "Time wasted: 0:41:28.880999\n",
      "\n",
      "number of neighnours is: 4\n",
      "Score: 0.0016897468347376213\n",
      "Time wasted: 0:50:51.424713\n",
      "\n",
      "number of neighnours is: 5\n",
      "Score: 0.0015985556645066075\n",
      "Time wasted: 0:50:44.023883\n",
      "\n",
      "number of neighnours is: 6\n",
      "Score: 0.0015849023490285632\n",
      "Time wasted: 0:48:57.726563\n",
      "\n",
      "number of neighnours is: 7\n",
      "Score: 0.0015981778541932009\n",
      "Time wasted: 0:48:55.005380\n",
      "\n",
      "number of neighnours is: 8\n",
      "Score: 0.0015791861255745978\n",
      "Time wasted: 0:48:51.265709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_scores = []\n",
    "\n",
    "for neigh in np.arange(2,9): #господи сколько я тут просижу то с такими параметрами\n",
    "    print(\"number of neighnours is:\", neigh)\n",
    "    new_knn = KNeighborsClassifier(metric = 'manhattan', weights = 'distance', n_neighbors = neigh)\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    score_x = cross_val_score(new_knn, X, y, scoring=\"f1\").mean()\n",
    "    print('Score:', score_x)\n",
    "    print('Time wasted:', datetime.datetime.now() - start)\n",
    "    new_scores.append(score_x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1efa1e46310>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(2,9), new_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем результаты\n",
    "\n",
    "С учетом выбранной метрики лучшим оказалось решение выбора логистчиеской регрессии с параметрами 'penalty': 'l1', 'solver': 'liblinear' и c = 0.01\n",
    "\n",
    "Но меня очень пугает решение через KNN - аномально низкая точность (такое ощущение, что я что-то не так сделал)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### На первоначальном тесте const показал для данной f1 точность 0 - ввиду этого тестить его сейчас смысла нет вообще"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnQpUAlNsu4D"
   },
   "source": [
    "# 2 - Небинарная классификация на вашем датасете (суммарно 6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUYfrIQFsu4D"
   },
   "source": [
    "### (2 балла) Выберите какой-нибудь интересный вам датасет, скачайте его и считайте данные\n",
    "\n",
    "Творческое задание - найти в интернете (или собрать свой даже) датасет, сохранить его в файл, и загрузить сюда.\n",
    "\n",
    "Требования:\n",
    "\n",
    "- он должен быть немаленький (хотя бы 500 объектов, лучше больше)\n",
    "- он должен быть интересный\n",
    "- таргет должен быть небинарным классом\n",
    "\n",
    "Минус балл, если ваш датасет с кем-нибудь повторится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKrkhO6tsu4D"
   },
   "source": [
    "У нас будет датасет предсказания потребления домами эл. энергии\n",
    "\n",
    "Ключевая колонка - Heating_Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "uaB7UqQwsu4D"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative_Compactness</th>\n",
       "      <th>Surface_Area</th>\n",
       "      <th>Wall_Area</th>\n",
       "      <th>Roof_Area</th>\n",
       "      <th>Overall_Height</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Glazing_Area</th>\n",
       "      <th>Glazing_Area_Distribution</th>\n",
       "      <th>Heating_Load</th>\n",
       "      <th>Cooling_Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>17.88</td>\n",
       "      <td>21.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.44</td>\n",
       "      <td>17.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.48</td>\n",
       "      <td>16.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.64</td>\n",
       "      <td>16.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Relative_Compactness  Surface_Area  Wall_Area  Roof_Area  Overall_Height  \\\n",
       "0                    0.98         514.5      294.0     110.25             7.0   \n",
       "1                    0.98         514.5      294.0     110.25             7.0   \n",
       "2                    0.98         514.5      294.0     110.25             7.0   \n",
       "3                    0.98         514.5      294.0     110.25             7.0   \n",
       "4                    0.90         563.5      318.5     122.50             7.0   \n",
       "..                    ...           ...        ...        ...             ...   \n",
       "763                  0.64         784.0      343.0     220.50             3.5   \n",
       "764                  0.62         808.5      367.5     220.50             3.5   \n",
       "765                  0.62         808.5      367.5     220.50             3.5   \n",
       "766                  0.62         808.5      367.5     220.50             3.5   \n",
       "767                  0.62         808.5      367.5     220.50             3.5   \n",
       "\n",
       "     Orientation  Glazing_Area  Glazing_Area_Distribution  Heating_Load  \\\n",
       "0              2           0.0                          0         15.55   \n",
       "1              3           0.0                          0         15.55   \n",
       "2              4           0.0                          0         15.55   \n",
       "3              5           0.0                          0         15.55   \n",
       "4              2           0.0                          0         20.84   \n",
       "..           ...           ...                        ...           ...   \n",
       "763            5           0.4                          5         17.88   \n",
       "764            2           0.4                          5         16.54   \n",
       "765            3           0.4                          5         16.44   \n",
       "766            4           0.4                          5         16.48   \n",
       "767            5           0.4                          5         16.64   \n",
       "\n",
       "     Cooling_Load  \n",
       "0           21.33  \n",
       "1           21.33  \n",
       "2           21.33  \n",
       "3           21.33  \n",
       "4           28.28  \n",
       "..            ...  \n",
       "763         21.40  \n",
       "764         16.88  \n",
       "765         17.11  \n",
       "766         16.61  \n",
       "767         16.03  \n",
       "\n",
       "[768 rows x 10 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"energy_efficiency_data.csv\", delimiter = ',')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Relative_Compactness       768 non-null    float64\n",
      " 1   Surface_Area               768 non-null    float64\n",
      " 2   Wall_Area                  768 non-null    float64\n",
      " 3   Roof_Area                  768 non-null    float64\n",
      " 4   Overall_Height             768 non-null    float64\n",
      " 5   Orientation                768 non-null    int64  \n",
      " 6   Glazing_Area               768 non-null    float64\n",
      " 7   Glazing_Area_Distribution  768 non-null    int64  \n",
      " 8   Heating_Load               768 non-null    float64\n",
      " 9   Cooling_Load               768 non-null    float64\n",
      "dtypes: float64(8), int64(2)\n",
      "memory usage: 60.1 KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relative_Compactness         0\n",
       "Surface_Area                 0\n",
       "Wall_Area                    0\n",
       "Roof_Area                    0\n",
       "Overall_Height               0\n",
       "Orientation                  0\n",
       "Glazing_Area                 0\n",
       "Glazing_Area_Distribution    0\n",
       "Heating_Load                 0\n",
       "Cooling_Load                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(columns = ['Cooling_Load'])\n",
    "X = df1.drop(columns = ['Heating_Load'])\n",
    "y = df1['Heating_Load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative_Compactness</th>\n",
       "      <th>Surface_Area</th>\n",
       "      <th>Wall_Area</th>\n",
       "      <th>Roof_Area</th>\n",
       "      <th>Overall_Height</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Glazing_Area</th>\n",
       "      <th>Glazing_Area_Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>1.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Relative_Compactness  Surface_Area  Wall_Area  Roof_Area  Overall_Height  \\\n",
       "0                     1.0         514.0      294.0      110.0             7.0   \n",
       "1                     1.0         514.0      294.0      110.0             7.0   \n",
       "2                     1.0         514.0      294.0      110.0             7.0   \n",
       "3                     1.0         514.0      294.0      110.0             7.0   \n",
       "4                     1.0         564.0      318.0      122.0             7.0   \n",
       "..                    ...           ...        ...        ...             ...   \n",
       "763                   1.0         784.0      343.0      220.0             4.0   \n",
       "764                   1.0         808.0      368.0      220.0             4.0   \n",
       "765                   1.0         808.0      368.0      220.0             4.0   \n",
       "766                   1.0         808.0      368.0      220.0             4.0   \n",
       "767                   1.0         808.0      368.0      220.0             4.0   \n",
       "\n",
       "     Orientation  Glazing_Area  Glazing_Area_Distribution  \n",
       "0              2           0.0                          0  \n",
       "1              3           0.0                          0  \n",
       "2              4           0.0                          0  \n",
       "3              5           0.0                          0  \n",
       "4              2           0.0                          0  \n",
       "..           ...           ...                        ...  \n",
       "763            5           0.0                          5  \n",
       "764            2           0.0                          5  \n",
       "765            3           0.0                          5  \n",
       "766            4           0.0                          5  \n",
       "767            5           0.0                          5  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.round()\n",
    "X = X.round()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative_Compactness</th>\n",
       "      <th>Surface_Area</th>\n",
       "      <th>Wall_Area</th>\n",
       "      <th>Roof_Area</th>\n",
       "      <th>Overall_Height</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Glazing_Area</th>\n",
       "      <th>Glazing_Area_Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>1.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Relative_Compactness  Surface_Area  Wall_Area  Roof_Area  Overall_Height  \\\n",
       "334                   1.0         808.0      368.0      220.0             4.0   \n",
       "139                   1.0         784.0      343.0      220.0             4.0   \n",
       "485                   1.0         564.0      318.0      122.0             7.0   \n",
       "547                   1.0         637.0      343.0      147.0             7.0   \n",
       "18                    1.0         637.0      343.0      147.0             7.0   \n",
       "..                    ...           ...        ...        ...             ...   \n",
       "71                    1.0         662.0      416.0      122.0             7.0   \n",
       "106                   1.0         588.0      294.0      147.0             7.0   \n",
       "270                   1.0         710.0      270.0      220.0             4.0   \n",
       "435                   1.0         514.0      294.0      110.0             7.0   \n",
       "102                   1.0         564.0      318.0      122.0             7.0   \n",
       "\n",
       "     Orientation  Glazing_Area  Glazing_Area_Distribution  \n",
       "334            4           0.0                          1  \n",
       "139            5           0.0                          2  \n",
       "485            3           0.0                          5  \n",
       "547            5           0.0                          1  \n",
       "18             4           0.0                          0  \n",
       "..           ...           ...                        ...  \n",
       "71             5           0.0                          1  \n",
       "106            4           0.0                          2  \n",
       "270            4           0.0                          5  \n",
       "435            5           0.0                          4  \n",
       "102            4           0.0                          2  \n",
       "\n",
       "[537 rows x 8 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334    15.0\n",
       "139    15.0\n",
       "485    32.0\n",
       "547    42.0\n",
       "18     30.0\n",
       "       ... \n",
       "71     32.0\n",
       "106    26.0\n",
       "270    11.0\n",
       "435    29.0\n",
       "102    29.0\n",
       "Name: Heating_Load, Length: 537, dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTi3XXsQsu4E"
   },
   "source": [
    "### (2 балла) Обучите несколько моделей, посмотрите на метрики.\n",
    "Как модели точно возьмите LogisticRegression, KNN и константу, можете придумать еще какие-нибудь.\n",
    "\n",
    "Как метрики точно возьмите accuracy, разные усреднения precision, recall и f1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "9sqX20mPsu4E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000) \n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "y_pred_proba_log_reg = log_reg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.54519389e-07, 6.96523794e-03, 3.15817202e-02, ...,\n",
       "        3.53671918e-06, 3.85012299e-04, 9.79595673e-05],\n",
       "       [1.48579657e-04, 5.47975233e-02, 4.77812362e-03, ...,\n",
       "        7.41318804e-10, 2.20988526e-07, 8.29415269e-08],\n",
       "       [1.58624115e-16, 2.09701073e-09, 6.13619441e-06, ...,\n",
       "        3.17896225e-02, 3.13717703e-02, 1.31220070e-02],\n",
       "       ...,\n",
       "       [1.77275807e-09, 3.38629090e-04, 1.29710069e-02, ...,\n",
       "        4.40352271e-03, 3.59407570e-02, 1.44049526e-02],\n",
       "       [8.49263647e-06, 3.96125379e-02, 2.03946193e-02, ...,\n",
       "        5.71029003e-08, 1.08057375e-05, 3.14432702e-06],\n",
       "       [4.70036265e-12, 1.08805540e-05, 2.05279990e-03, ...,\n",
       "        1.12604053e-02, 5.79679232e-02, 2.04447820e-02]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSgrHH_Dsu4E"
   },
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0.2, 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       ...,\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "y_pred_proba_knn = knn.predict_proba(X_test)\n",
    "y_pred_proba_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Самый мощный класс решений - const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({15.0: 56,\n",
       "         32.0: 29,\n",
       "         42.0: 9,\n",
       "         30.0: 14,\n",
       "         43.0: 3,\n",
       "         13.0: 46,\n",
       "         10.0: 13,\n",
       "         11.0: 39,\n",
       "         24.0: 22,\n",
       "         31.0: 3,\n",
       "         6.0: 4,\n",
       "         40.0: 15,\n",
       "         36.0: 15,\n",
       "         14.0: 34,\n",
       "         12.0: 37,\n",
       "         37.0: 16,\n",
       "         29.0: 28,\n",
       "         16.0: 7,\n",
       "         19.0: 8,\n",
       "         17.0: 26,\n",
       "         27.0: 6,\n",
       "         33.0: 23,\n",
       "         26.0: 14,\n",
       "         18.0: 5,\n",
       "         25.0: 15,\n",
       "         20.0: 2,\n",
       "         39.0: 9,\n",
       "         28.0: 11,\n",
       "         41.0: 6,\n",
       "         8.0: 3,\n",
       "         35.0: 5,\n",
       "         7.0: 6,\n",
       "         38.0: 2,\n",
       "         34.0: 1,\n",
       "         21.0: 2,\n",
       "         23.0: 3})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "       15., 15., 15., 15., 15., 15., 15., 15., 15., 15.])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [15.0]*len(X_test)\n",
    "y_pred_const = np.array(a)\n",
    "y_pred_proba_const = y_pred_const\n",
    "y_pred_proba_const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1341991341991342\n",
      "0.11688311688311688\n",
      "0.07792207792207792\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_log_reg))\n",
    "print(accuracy_score(y_test, y_pred_knn))\n",
    "print(accuracy_score(y_test, y_pred_const))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08638982849509165\n",
      "0.12889040783777628\n",
      "0.0023612750885478157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(precision_score(y_test, y_pred_knn, average='macro'))\n",
    "print(precision_score(y_test, y_pred_const, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1341991341991342\n",
      "0.11688311688311688\n",
      "0.07792207792207792\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_pred_log_reg, average='micro'))\n",
    "print(precision_score(y_test, y_pred_knn, average='micro'))\n",
    "print(precision_score(y_test, y_pred_const, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10676911719692468\n",
      "0.12072052082865233\n",
      "0.030303030303030304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(recall_score(y_test, y_pred_knn, average='macro'))\n",
    "print(recall_score(y_test, y_pred_const, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1341991341991342\n",
      "0.11688311688311688\n",
      "0.07792207792207792\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test, y_pred_log_reg, average='micro'))\n",
    "print(recall_score(y_test, y_pred_knn, average='micro'))\n",
    "print(recall_score(y_test, y_pred_const, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07686380063526138\n",
      "0.1196907805236167\n",
      "0.1196907805236167\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(f1_score(y_test, y_pred_knn, average='macro'))\n",
    "print(f1_score(y_test, y_pred_knn, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1341991341991342\n",
      "0.11688311688311688\n",
      "0.07792207792207792\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred_log_reg, average='micro'))\n",
    "print(f1_score(y_test, y_pred_knn, average='micro'))\n",
    "print(f1_score(y_test, y_pred_const, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38Bw9W6Qsu4E"
   },
   "source": [
    "### (2 балла) Выберите метрику, которую вы хотите максимизировать. Переберите гиперпараметры, постарайтесь найти модель, которая максимизирует эту метрику.\n",
    "\n",
    "Обоснуйте свой выбор. Напишите красивый отчет с графиками. Добились ли вы результатов, которых хотели добиться для этого датасета?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз, в отличие от прошлой задачи, мы уже можем не заботиться о домах, попавших не в ту категорию - тут бы дай бог просто что-то угадать да побольше; поэтому возьмем метрику recall micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "85c16tl5su4E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best: {'C': 20.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "recall micro: 0.23091034960193837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x =[0.01, 0.1, 1, 10, 15, 20, 50, 100, 200]\n",
    "c = np.array(x)\n",
    "\n",
    "grid = {'C': c, \n",
    "        'penalty': ['l1', 'l2'], \n",
    "        \"solver\": ['liblinear', 'saga']}\n",
    "log_reg = LogisticRegression(max_iter = 3000)\n",
    "log_reg_cv = GridSearchCV(log_reg, grid, scoring=\"recall_micro\")\n",
    "log_reg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"best:\", log_reg_cv.best_params_)\n",
    "print(\"recall micro:\", log_reg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "GhlfphAmsu4F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "recall: 0.17872966424368295\n"
     ]
    }
   ],
   "source": [
    "grid_knn = {'n_neighbors': np.arange(2, 9), \n",
    "            'weights': ['uniform', 'distance'], \n",
    "            'metric': ['euclidean', 'manhattan']}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, grid_knn, scoring=\"recall_micro\")\n",
    "knn_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"best:\", knn_cv.best_params_)\n",
    "print(\"recall:\", knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Раз я все равно опоздал, то посмотрим на случайный лес сразу "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best: {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 10}\n",
      "recall: 0.23838698511595707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param = { 'n_estimators': np.arange (10, 51, 10),\n",
    "              'max_depth': np.arange (1,10),\n",
    "              'min_samples_leaf': np.arange (1,8),\n",
    "              'min_samples_split': np.arange (2,10) }\n",
    "rf = RandomForestClassifier()\n",
    "rf_cv = GridSearchCV(rf, param, scoring=\"recall_micro\")\n",
    "rf_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"best:\", rf_cv.best_params_)\n",
    "print(\"recall:\", rf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоги по заданию:\n",
    "1. Для датасета лучшей моделью оказался случайный лес с параметрами: 'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 10\n",
    "2. Изначальная точность была увеличена с 0.13 до почти 0.24 -> почти в 2 раза\n",
    "3. Из-за отсутствия фича инженеринга и не самого удачного датасета получается невысокая точность -> стоит проводить более тщательный анализ\n",
    "4. Рандомный лес рулит\n",
    "5. Нельзя отклыдвать дз на последний момент"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw_classification",
   "provenance": [
    {
     "file_id": "1kuo6m_KwVUmVJeBTg0I2M-saD-w_9-Zf",
     "timestamp": 1652384124542
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
