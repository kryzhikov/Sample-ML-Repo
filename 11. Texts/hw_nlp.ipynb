{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import pos_tag, WordNetLemmatizer\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('nlp/train.csv', encoding='unicode_escape') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2351 entries, 0 to 2350\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Id            2351 non-null   int64  \n",
      " 1   Hotel_name    2351 non-null   object \n",
      " 2   Review_Title  2136 non-null   object \n",
      " 3   Review_Text   2351 non-null   object \n",
      " 4   Rating        2351 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 92.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0\n",
       "Hotel_name        0\n",
       "Review_Title    215\n",
       "Review_Text       0\n",
       "Rating            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выкинем все строки, содержащие NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['Review_Title'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Hotel_name</th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Park Hyatt</td>\n",
       "      <td>Refuge in Chennai</td>\n",
       "      <td>Excellent room and exercise facility. All arou...</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hilton Chennai</td>\n",
       "      <td>Hilton Chennai</td>\n",
       "      <td>Very comfortable and felt safe. \\r\\nStaff were...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Royal Regency</td>\n",
       "      <td>No worth the rating shown in websites. Pricing...</td>\n",
       "      <td>Not worth the rating shown. Service is not goo...</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>Good stay</td>\n",
       "      <td>First of all nice &amp; courteous staff, only one ...</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Park Hyatt</td>\n",
       "      <td>Needs improvement</td>\n",
       "      <td>Overall ambience of the hotel is very good. In...</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Everest</td>\n",
       "      <td>Good atmosphere, food and drinks not available</td>\n",
       "      <td>I reached the hotel by car, felt good for co-o...</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Metro Grand</td>\n",
       "      <td>Lovely hotel</td>\n",
       "      <td>The hotel is pretty clean with excellent beddi...</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Oyo Rooms Anna Arch Arumbakkam</td>\n",
       "      <td>Not worth the money</td>\n",
       "      <td>No hot water.wifi limited to lobby. Average cl...</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>FabHotel Priyadarshini Park Mount Road</td>\n",
       "      <td>Good hotel with poor services</td>\n",
       "      <td>Location and cleanliness is good. But as far a...</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Treebo J's Five Two Boutique</td>\n",
       "      <td>Good appearance &amp; amazing hotel to stay</td>\n",
       "      <td>It's amazing and I got so many benefits from t...</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id                              Hotel_name  \\\n",
       "0    0                              Park Hyatt   \n",
       "1    1                          Hilton Chennai   \n",
       "2    2                       The Royal Regency   \n",
       "3    3                                  Rivera   \n",
       "4    4                              Park Hyatt   \n",
       "5    5                                 Everest   \n",
       "6    6                             Metro Grand   \n",
       "7    7          Oyo Rooms Anna Arch Arumbakkam   \n",
       "9    9  FabHotel Priyadarshini Park Mount Road   \n",
       "10  10            Treebo J's Five Two Boutique   \n",
       "\n",
       "                                         Review_Title  \\\n",
       "0                                   Refuge in Chennai   \n",
       "1                                      Hilton Chennai   \n",
       "2   No worth the rating shown in websites. Pricing...   \n",
       "3                                           Good stay   \n",
       "4                                   Needs improvement   \n",
       "5      Good atmosphere, food and drinks not available   \n",
       "6                                        Lovely hotel   \n",
       "7                                 Not worth the money   \n",
       "9                       Good hotel with poor services   \n",
       "10            Good appearance & amazing hotel to stay   \n",
       "\n",
       "                                          Review_Text  Rating  \n",
       "0   Excellent room and exercise facility. All arou...    80.0  \n",
       "1   Very comfortable and felt safe. \\r\\nStaff were...   100.0  \n",
       "2   Not worth the rating shown. Service is not goo...    71.0  \n",
       "3   First of all nice & courteous staff, only one ...    86.0  \n",
       "4   Overall ambience of the hotel is very good. In...    86.0  \n",
       "5   I reached the hotel by car, felt good for co-o...    71.0  \n",
       "6   The hotel is pretty clean with excellent beddi...    80.0  \n",
       "7   No hot water.wifi limited to lobby. Average cl...    40.0  \n",
       "9   Location and cleanliness is good. But as far a...    57.0  \n",
       "10  It's amazing and I got so many benefits from t...    86.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая будет обрабатывать текст из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    my_switch = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'V': wordnet.VERB,\n",
    "        'N': wordnet.NOUN,\n",
    "        'R': wordnet.ADV,\n",
    "    }\n",
    "    for key, item in my_switch.items():\n",
    "        if treebank_tag.startswith(key):\n",
    "            return item\n",
    "    return wordnet.NOUN\n",
    "\n",
    "\n",
    "def clean_text(text, normalizer='stem'):\n",
    "    \"\"\" Cleans text\n",
    "    \"\"\"\n",
    "    assert(normalizer=='stem' or normalizer=='lem')\n",
    "\n",
    "    text = text.lower()\n",
    "    # tokenize\n",
    "    text = [w for w in re.split(r'[&;,.\\s]',text)]\n",
    "\n",
    "    # remove numbers\n",
    "    text = [w for w in text if not any(c.isdigit() for c in w)]\n",
    "    \n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [w for w in text if w not in stop]\n",
    "\n",
    "    # remove empty tokens\n",
    "    text = [w for w in text if len(w) > 0]\n",
    "\n",
    "    # normalize\n",
    "    if normalizer == 'stem':\n",
    "        stemmer = SnowballStemmer(language='english', ignore_stopwords=True)\n",
    "        text = [stemmer.stem(w) for w in text]\n",
    "    else:\n",
    "        # pos tag text\n",
    "        pos_tags = pos_tag(text)\n",
    "        # lemmatize text\n",
    "        text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "\n",
    "    # remove words with only one letter\n",
    "    text = [w for w in text if len(w) > 1]\n",
    "\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработаем текст признаков `Review_Text` и `Review_Title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = 'lem'\n",
    "train_df['Review_Text_Clean'] = train_df['Review_Text'].apply(lambda x: clean_text(x, normalizer))\n",
    "train_df['Review_Title_Clean'] = train_df['Review_Title'].apply(lambda x: clean_text(x, normalizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling based only on text\n",
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим все текстовые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = train_df['Review_Text_Clean'] + train_df['Review_Title_Clean']\n",
    "y_train = train_df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1,1))\n",
    "X_text_cv = count_vect.fit_transform(np.copy(X_text))\n",
    "# count_vect.vocabulary_\n",
    "\n",
    "idf_vect1 = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_text_tv1 = idf_vect1.fit_transform(np.copy(X_text))\n",
    "\n",
    "idf_vect2 = TfidfVectorizer(ngram_range=(1,2))\n",
    "X_text_tv2 = idf_vect2.fit_transform(np.copy(X_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SGD Regressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV score SGDRegressor + CountVectorizer = 24.76\n",
      "Average CV score SGDRegressor + TfidfVectorizer with ngram 1 = 16.73\n",
      "Average CV score SGDRegressor + TfidfVectorizer with ngram 2 = 15.76\n"
     ]
    }
   ],
   "source": [
    "sgd_reg = SGDRegressor(random_state=42, max_iter=2000)\n",
    "# reg = RandomForestRegressor(random_state=42)\n",
    "cvs_sgd_cv = cross_val_score(sgd_reg, X_text_cv, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cvs_sgd_tv1 = cross_val_score(sgd_reg, X_text_tv1, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cvs_sgd_tv2 = cross_val_score(sgd_reg, X_text_tv2, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "print(f\"Average CV score SGDRegressor + CountVectorizer = {np.mean(-cvs_sgd_cv):.2f}\")\n",
    "print(f\"Average CV score SGDRegressor + TfidfVectorizer with ngram 1 = {np.mean(-cvs_sgd_tv1):.2f}\")\n",
    "print(f\"Average CV score SGDRegressor + TfidfVectorizer with ngram 2 = {np.mean(-cvs_sgd_tv2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Decision Trees`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV score Decision Tree + CountVectorizer = 18.10\n",
      "Average CV score Decision Tree + TfidfVectorizer with ngram 1 = 18.25\n",
      "Average CV score Decision Tree + TfidfVectorizer with ngram 2 = 18.87\n"
     ]
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor(random_state=42, max_depth=12)\n",
    "cvs_tree_cv = cross_val_score(tree_reg, X_text_cv, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cvs_tree_tv1 = cross_val_score(tree_reg, X_text_tv1, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cvs_tree_tv2 = cross_val_score(tree_reg, X_text_tv2, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "print(f\"Average CV score Decision Tree + CountVectorizer = {np.mean(-cvs_tree_cv):.2f}\")\n",
    "print(f\"Average CV score Decision Tree + TfidfVectorizer with ngram 1 = {np.mean(-cvs_tree_tv1):.2f}\")\n",
    "print(f\"Average CV score Decision Tree + TfidfVectorizer with ngram 2 = {np.mean(-cvs_tree_tv2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV score Random Forest + CountVectorizer = 16.64\n",
      "Average CV score Random Forest + TfidfVectorizer with ngram 1 = 16.51\n",
      "Average CV score Random Forest + TfidfVectorizer with ngram 2 = 16.52\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(random_state=42, max_depth=12)\n",
    "cvs_rf_cv = cross_val_score(rf_reg, X_text_cv, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cvs_rf_tv1 = cross_val_score(rf_reg, X_text_tv1, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cvs_rf_tv2 = cross_val_score(rf_reg, X_text_tv2, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "print(f\"Average CV score Random Forest + CountVectorizer = {np.mean(-cvs_rf_cv):.2f}\")\n",
    "print(f\"Average CV score Random Forest + TfidfVectorizer with ngram 1 = {np.mean(-cvs_rf_tv1):.2f}\")\n",
    "print(f\"Average CV score Random Forest + TfidfVectorizer with ngram 2 = {np.mean(-cvs_rf_tv2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100\n",
    "\n",
    "text_corpus = [x.split(\" \") for x in X_text]\n",
    "w2v = Word2Vec(text_corpus, min_count=1, sg=1, vector_size=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_w2v = [np.mean([w2v.wv[w] for w in review.split(\" \")], axis=0) for review in X_text]\n",
    "X_text_w2v = np.vstack(X_text_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV score SGD + Word2Vec = 18.05\n",
      "Average CV score Tree + Word2Vec = 18.10\n",
      "Average CV score Random Forest + Word2Vec = 16.64\n"
     ]
    }
   ],
   "source": [
    "cvs_sgd_w2v = cross_val_score(sgd_reg, X_text_w2v, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cvs_tree_w2v = cross_val_score(tree_reg, X_text_cv, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cvs_rf_w2v = cross_val_score(rf_reg, X_text_cv, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "print(f\"Average CV score SGD + Word2Vec = {np.mean(-cvs_sgd_w2v):.2f}\")\n",
    "print(f\"Average CV score Tree + Word2Vec = {np.mean(-cvs_tree_w2v):.2f}\")\n",
    "print(f\"Average CV score Random Forest + Word2Vec = {np.mean(-cvs_rf_w2v):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling using all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем новые признаки из текстовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество слов \n",
    "train_df['Review_Text_Count'] = train_df['Review_Text'].apply(lambda x: len(x.split(\" \")))\n",
    "train_df['Review_Title_Count'] = train_df['Review_Title'].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сентимент\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "sid.polarity_scores(train_df['Review_Text_Clean'][0])\n",
    "\n",
    "X_text_sent = X_text.apply(lambda review: sid.polarity_scores(review))\n",
    "X_text_comp = X_text_sent.apply(lambda score_dict: score_dict['compound'])\n",
    "X_text_comp = X_text_comp.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем категориальный признак `Hotel_name` в OneHotVector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_counts = train_df[['Review_Title_Count', 'Review_Text_Count']]\n",
    "scalar = StandardScaler()\n",
    "X_counts = scalar.fit_transform(X_counts)\n",
    "\n",
    "X_names = pd.get_dummies(train_df['Hotel_name'], sparse=True).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack((X_text_w2v, X_names, X_counts, X_text_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV score SGD = 15.92\n",
      "Average CV score Tree = 18.33\n",
      "Average CV score Random Forest = 14.28\n"
     ]
    }
   ],
   "source": [
    "sgd_reg = SGDRegressor(random_state=42, max_iter=3000)\n",
    "tree_reg = DecisionTreeRegressor(random_state=42, max_depth=12)\n",
    "rf_reg = RandomForestRegressor(random_state=42, max_depth=12)\n",
    "\n",
    "cvs_sgd = cross_val_score(sgd_reg, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cvs_tree = cross_val_score(tree_reg, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cvs_rf = cross_val_score(rf_reg, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "print(f\"Average CV score SGD = {np.mean(-cvs_sgd):.2f}\")\n",
    "print(f\"Average CV score Tree = {np.mean(-cvs_tree):.2f}\")\n",
    "print(f\"Average CV score Random Forest = {np.mean(-cvs_rf):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "Я оценивал качество моделей на основе `cross_val_score`, хотя можно было бы и разбить на трейн тест сет, но из-за небольшой выборки я не стал этого делать. \n",
    "\n",
    "Я попробовал применить стемминг и лемматизацию, большой разницы не увидел между ними в плане `cross_val_score`. В плане векторизации я попробовал `Countvectorizer`, `TfidfVectorizer` и `Word2Vec`; для `TfidfVectorizer` попробовал 1 и 2 нграммы.  `cross_val_score` у `TfidfVectorizer` и `Word2Vec` были самыми лучшими. Однако у `Word2Vec` размерность вектора намного меньше чем у `TfidfVectorizer`, особенно когда используем 2 н-граммы. Так как отличие в метрике не большое, то лучше в дальнейшем я использовал `Word2Vec` признаки. \n",
    "\n",
    "Я попробовал вытащить из текста новые признаки, например количество слов в отзыве и названии отзыва, а также оценку сентимента. Думаю, именно оценка сентимента дал небольшой прирост к метрике. В целом все полученные модели плохо предсказывают оценку рейтинга. Это может быть связана с тем, что данных мало."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
