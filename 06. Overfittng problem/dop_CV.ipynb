{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9fbb36",
   "metadata": {},
   "source": [
    "# Разъяснения по CrossValidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1865f452",
   "metadata": {},
   "source": [
    "Как организовать выборки для кроссвалидации:\n",
    "__1)__ Выбираем количество фолдов. Чем меньше выборка - тем больше фолдов. \\\n",
    "__2)__ Бъём на фолды. Получаем следующее: \n",
    "\n",
    "![CV](https://www.machinelearningmastery.ru/img/0-752547-79267.png)\n",
    "<p style=\"text-align: center;\"></p>\n",
    "\n",
    "__3)__ Итеративно обучаемся на зеленом и тестируемся на красном"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7fec43",
   "metadata": {},
   "source": [
    "### Что нам это даёт?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeeadbd",
   "metadata": {},
   "source": [
    "Основная цель, которую мы приследуем - подбор оптимальных гиперпараметров. \\\n",
    "Представим, что мы выбрали некоторую модель, для определенности полиномиальная регрессия. Мы выбрали гиперпараметры степень многочлена и learning rate градиентного спуска. Обучились без кроссвалидации, сделали предсказания и получили ошибку $\\xi_0$. Если отнестись к ошибке, как к случайной величине, то можно сделать вывод, что она непрерывная, тогда какова вероятность получить такую ошибку? \\\n",
    "Пусть данная случайная величина имеет плотность распределения $f_{\\xi}(x)$. Тогда: $\\mathbb{P}(error=\\xi_0) = \\mathbb{P}(\\xi_0 \\leq error \\leq \\xi_0) = \\int\\limits_{\\xi_0}^{\\xi_0}f_{\\xi}(x)dx = 0$ \\\n",
    "То есть наша точечная оценка ошибки $\\xi_0$, можно считать, не является информативной. Кроссвалидация помогает исправить данную проблему. \\\n",
    "Мы фиксируем гиперпараметры и __при фиксированных гиперпараметрах__ итеративно обучаем на \"зеленом\" и тестируем на \"красном\". Получаем n оценок ошибок __конкретного семейства моделей__ (мы выбрали полиномиальную регрессию) __при фиксированных гиперпараметрах__. Имея целую выборку ошибок, мы уже можем получить более информативные статистики такие, как среднее, медиана, разброс, дисперсия, среднее отклонение от ошибки на тренировочной выборке и так далее (для более опытных в мат. стате можно пробовать строить доверительные интервалы)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b005b",
   "metadata": {},
   "source": [
    "### Какая итоговая модель?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3609f5",
   "metadata": {},
   "source": [
    "Тут у вас два варианта. \n",
    "\n",
    "- После всех кроссвалидаций вы получили оптимальный набор гиперпараметров. Берём данный набор и обучаем на всей выборке. Это и будет итоговая модель\n",
    "- Вы нашли оптимальный набор гиперпараметров и при этом наборе оптимальных параметров, блягодаря кроссвалидации, вы получили n моделей, можно сделать из них ансамбль, например, усреднить их предсказания - это и будет итоговой моделью"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
